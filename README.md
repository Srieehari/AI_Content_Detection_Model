Here's the **README.md** file in the correct format for you to copy and paste:

```md
# LLM Content Classification

This repository contains scripts and data for a project that classifies text based on:
1. **Content Type** – Code, Essay, Poetry, or Story.
2. **Source** – BARD, GPT, or Human.

The project demonstrates how to:
- Load and preprocess data from different sources.
- Tokenize and encode text using a Transformer-based model (ALBERT).
- Train and evaluate separate models for each content type to classify the origin of the text.
- Save the trained models and tokenizer for later usage.

---

## Table of Contents
- [Project Overview](#project-overview)
- [Data Organization](#data-organization)
- [Requirements](#requirements)
- [Usage](#usage)
- [Training the Models](#training-the-models)
- [Evaluation](#evaluation)
- [Saving the Models](#saving-the-models)
- [Results](#results)
- [Directory Structure](#directory-structure)
- [License](#license)

---

## Project Overview

This project aims to classify texts generated by:
- **BARD** (Google’s LLM)
- **ChatGPT** (OpenAI’s LLM)
- **Human Authors**

We work with four categories of content:
1. **Code**
2. **Essay**
3. **Poetry**
4. **Story**

Each category is handled by a separate ALBERT model fine-tuned on relevant data. This allows more targeted classification and better performance for each content type.

---

## Data Organization

Data is stored in the `data` folder, structured as follows:

```
data/
├── BARD
│   ├── BARD_essay.csv
│   ├── BARD_poetry.csv
│   ├── BARD_pycode.csv
│   └── BARD_story.csv
├── GPT
│   ├── ChatGPT_essay.csv
│   ├── ChatGPT_poetry.csv
│   ├── ChatGPT_pycode.csv
│   └── ChatGPT_story.csv
└── Human
    ├── human_essay_1.csv
    ├── human_essay_2.csv
    ├── human_essay_hewlett.csv
    ├── human_essay_hugg.csv
    ├── human_poetry.csv
    ├── human_code.csv
    └── human_stories.csv
```

**Note:** Each CSV file may have slightly different structures (e.g., `prompts` + `responses`, or `Title` + `Chapter_text`). The loading functions handle these varied structures.

---

## Requirements

- Python 3.7+
- [PyTorch](https://pytorch.org/) (with GPU support recommended)
- [Transformers](https://github.com/huggingface/transformers)
- [scikit-learn](https://scikit-learn.org/)
- [numpy](https://numpy.org/)
- [pandas](https://pandas.pydata.org/)
- [matplotlib](https://matplotlib.org/)
- [nltk](https://www.nltk.org/)
- [tqdm](https://github.com/tqdm/tqdm)

Install dependencies using:

```bash
pip install torch transformers scikit-learn pandas numpy matplotlib nltk tqdm
```

---

## Usage

1. **Clone the Repository**  
   ```bash
   git clone https://github.com/sakibsh/LLM.git
   cd LLM
   ```

2. **Verify Data Files**  
   Inside `LLM/data/`, ensure that the BARD, GPT, and Human CSV files exist. If any files are missing, the script will skip them.

3. **Run the Main Script**  
   In a Python environment or notebook, run the script to:
   - Load and preprocess data
   - Split data into train/test sets
   - Tokenize text using a Transformer tokenizer
   - Train separate ALBERT models for each content type
   - Evaluate the models

---

## Training the Models

The training process consists of:

1. **Data Loading**  
   - Reads the BARD, GPT, and Human CSV files.
   - Merges them into a single dataset.

2. **Cleaning & Distribution Checks**  
   - Removes `NaN` values and trims whitespace.

3. **Train/Test Split**  
   - Data is split (80% train, 20% test) per content type.
   - Labels (`Human`, `BARD`, `GPT`) are mapped to integers.

4. **Tokenization**  
   - Uses ALBERT tokenizer with a max length of 512.

5. **Model Definition**  
   - Creates an ALBERT classification model with `num_labels=3`.

6. **Loss Function & Class Weights**  
   - Adjusts weights to balance class distribution.

7. **Training**  
   - Uses `AdamW` optimizer.
   - Tracks loss using `tqdm`.

---

## Evaluation

Each model is evaluated using:
- Accuracy, precision, recall, and F1-scores.
- Confusion matrices to analyze misclassifications.

Example output:

```bash
Classification Report for Essay:
              precision    recall  f1-score   support

       Human       0.85      0.90      0.87       500
        BARD       0.82      0.78      0.80       500
         GPT       0.88      0.85      0.86       500

    accuracy                           0.84      1500
```

---

## Saving the Models

After training, models are saved in the `trained_models` directory:

```
trained_models/
├── code_model.pth
├── essay_model.pth
├── poetry_model.pth
└── story_model.pth
```

The tokenizer is also saved for later usage.

---

## Results

- **Classification Accuracy**: Measures how well each model distinguishes between human vs. machine outputs.
- **Confusion Matrices**: Shows common misclassifications.

Fine-tuning, hyperparameter tuning, or using larger datasets can improve accuracy.

---

## Directory Structure

```
LLM/
├── data/
│   ├── BARD/
│   │   ├── BARD_essay.csv
│   │   ├── BARD_poetry.csv
│   │   ├── BARD_pycode.csv
│   │   └── BARD_story.csv
│   ├── GPT/
│   │   ├── ChatGPT_essay.csv
│   │   ├── ChatGPT_poetry.csv
│   │   ├── ChatGPT_pycode.csv
│   │   └── ChatGPT_story.csv
│   └── Human/
│       ├── human_essay_1.csv
│       ├── human_essay_2.csv
│       ├── human_essay_hewlett.csv
│       ├── human_essay_hugg.csv
│       ├── human_poetry.csv
│       ├── human_code.csv
│       └── human_stories.csv
├── trained_models/
│   ├── code_model.pth
│   ├── essay_model.pth
│   ├── poetry_model.pth
│   ├── story_model.pth
│   ├── tokenizer_config.json
│   ├── special_tokens_map.json
│   └── vocab.txt
├── README.md
└── [Python scripts / notebooks]
```

---

## License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and distribute this project.

---
